{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Ridge Regression and Lasso Regression are two popular techniques used in linear regression to address issues related to overfitting and multicollinearity, which are common challenges in predictive modeling and regression analysis.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of MSE: -0.0689701255462469\n"
     ]
    }
   ],
   "source": [
    "# Used for cross-validation and the scoring criteria used is mean_squared_error\n",
    "linear_regressor=LinearRegression()\n",
    "linear_regressor.fit(X,y)\n",
    "mse_score = cross_val_score(\n",
    "    linear_regressor, X, y, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "mean_mse = mse_score.mean()\n",
    "\n",
    "print(f\"Mean of MSE: {mean_mse}\")\n",
    "\n",
    "# Mean of MSE should be as close to 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Ridge and Lasso Regression\n",
    "\n",
    "**Ridge Regression** and **Lasso Regression** are two techniques used in linear regression to address issues related to overfitting and multicollinearity, common challenges in predictive modeling. They modify traditional linear regression by introducing regularization, adding penalty terms to the cost function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters={\"alpha\":(1e-15,1e-10,1e-5,1e-3,1e-2,1,5,3,10,20,25,50,75,100)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "\n",
    "- **Objective:** Ridge Regression, also known as L2 regularization, aims to find model parameters that fit the data well while keeping them small.\n",
    "\n",
    "- **Cost Function:** It adds a regularization term to the mean squared error (MSE) cost function:\n",
    "\n",
    "   ### J(θ)=MSE(θ) + α∑(θ)^2\n",
    "\n",
    "- **Why Use Ridge Regression:**\n",
    "  \n",
    "  1. **Prevents Overfitting:** Ridge Regression mitigates overfitting by penalizing large coefficients, leading to a simpler, more generalizable model.\n",
    "  \n",
    "  2. **Handles Multicollinearity:** It effectively addresses multicollinearity, reducing the impact of correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={'alpha': (1e-15, 1e-10, 1e-05, 0.001, 0.01, 1, 5, 3,\n",
       "                                   10, 20, 25, 50, 75, 100)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "ridge_regressor = GridSearchCV(\n",
    "    ridge, parameters, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# Fitting our model to data-set so to find the best_score\n",
    "ridge_regressor.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1}\n",
      "-0.04961936142257062\n"
     ]
    }
   ],
   "source": [
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression\n",
    "\n",
    "- **Objective:** Lasso Regression, also known as L1 regularization, seeks to find a model that fits the data well while keeping coefficients small.\n",
    "\n",
    "- **Cost Function:** It introduces a regularization term to the cost function:\n",
    "\n",
    "  ### J(θ)=MSE(θ) + α∑∣θ∣\n",
    "\n",
    "- **Why Use Lasso Regression:**\n",
    "\n",
    "  1. **Feature Selection:** Lasso Regression automatically selects relevant features by zeroing out less important coefficients.\n",
    "  \n",
    "  2. **Handles Multicollinearity:** It is effective in dealing with multicollinearity.\n",
    "  \n",
    "  3. **Simplifies the Model:** Lasso produces a simplified model with fewer variables, aiding interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={'alpha': (1e-15, 1e-10, 1e-05, 0.001, 0.01, 1, 5, 3,\n",
       "                                   10, 20, 25, 50, 75, 100)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "lasso_regressor = GridSearchCV(\n",
    "    ridge, parameters, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "# Fitting our model to data-set so to find the best_score\n",
    "lasso_regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1}\n",
      "-0.04961936142257062\n"
     ]
    }
   ],
   "source": [
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge and Lasso Regression are valuable tools when working with linear regression models, especially in situations where feature selection, multicollinearity, and overfitting are concerns. The choice between them depends on your specific problem, and you may need to fine-tune the regularization parameter α to find the optimal model for your data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
